# 100 Days Of Code - Log

### Day 1: July 28th, 2018 - Saturday

**Today's Progress** 
* Finished Coursera's University of Michigan Python Course - Course 2: Python Data Structures : Week 5

**Thoughts** 
* Still burning through what is basically review material. I learned about using dict.get(key,defaultValue) as an idiom for creating histograms without throwing a traceback if you look for a key that isn't in the dictionary yet. I felt a little strange reviewing basics that I've known for a long time, but clearly without coding regularly there are still a lot of methods and constructions that are new to me with some of the most common elements of the standard library.

**Link(s) to work**
* [Day 1 Exercises](exercises/day1.py)

### Day 2: July 29th, 2018 - Sunday

**Today's Progress**: 
* Finished Coursera's University of Michigan Python Course - Course 2: Python Data Structures
* Started Courera's University of Michigan Python Course - Course 3: Using Python to Access the Web: Weeks 1 and 2

**Thoughts**
* Got a better sense of how and when to use a tuple. Also learned that a major feature of tuples is that they're much more memory efficient because they hardle support any methods. 
* Figured out the difference between list.sort() and sorted()
* Really enjoyed watching interviews with the creators of jQuery and C++ and the "discoverer" of JSON.
* Also learned about "greedy" and "non-greedy" regex statements
* This part of the tutorial is still feeling relatively easy, though it takes me a minute to complete the exercises, especially the "just for fun" exercise which involved list comprehensions. Amazing, but for some reason sort of mind bending.

**Questions** 
* Study up on list comprehensions
* Learn more about primitives in different languages
* Learn more about the history of AJAX in different languages

**Link(s) to work**
* [Day 2 Exercises](exercises/day2.py)
* [More Day 2 Exercises](exercises/day2a.py)

### Day 3: July 30th, 2018 - Monday

**Today's Progress**: 
* Finished Coursera's University of Michigan Python Course - Course 3: Accessing the Web: Week 3

**Thoughts**
* Man was today a slow mover. Got stuck figuring out why set localecho doesn't work how I expect with the wonky Windows Telnet client, and then went down a Python documentation rabbit how. 
* Networking still confuses the hell out of me. I think it's largely a vocabulary issue. I want to unlock the mysteries, but I also question the usefulness considering how many amazing shortcuts already exist to do the tasks we want to do.

**Questions**
* What's the simplest way to grab HTTP headers in Python? urllib? requests?

**Link(s) to work**
* [Day 3 Exercises](exercises/day3.py)

### Day 4: July 31st, 2018 - Tuesday

**Today's Progress**: 
* Completed the lectures, quiz and one of the two activities for "Using Python to Access Web Data"
* I'll need to finish up the second example and then reviewing to take any other questions down and make sure I understand what it is I'm doing.

**Thoughts**
* Today was a long day, and it was hard to muster the gumption to put in the time starting shortly before 11pm. I think it was worth it? I mean, I enjoyed doing the activity, but morning comes at the same time regardless of when I go to bed.
* Things are starting to get really fun. Grabbing data from the web is such a practical and powerful skill. I can't wait to start using Beautiful Soup in my own projects.

**Questions** 
* What's the standard to deciding exactly how to import a library or module - especially when it just comes to how you'll call the module, no necessarily how many modules you're loading
* How many sites really have scraping policies? Where is that info kept? Is it ethical to write a spider to check for scraping policies?
* I didn't understand the import SSL bit from the example

**Link(s) to work**
* [Day 4 Exercises](exercises/day4.py)
* [More Day 4 Exercises](exercises/day4a.py)

### Day X:
**Today's Progress**: 
* Completed BeautifulSoup activities from "Using Python to Access Web Data"
* Completed the XML chapter from "Using Pything to Access Web Data"

**Thoughts**
* Still having lots of fun. It's really easy to stay up too late. BeautifulSoup is lots of fun and it was a sort of boring right turn to parsing XML. I've used Xpath in the path, so I see the use, but I'm excited to get to JSON tomorrow.
* I refactored my sample code using with and enumerate to shorten the code and be more Pythonic. That felt really good.

**Questions** 
* What is the full syntax is XPath? Is it a lot easier than just formally walking the whole tree?

**Link(s) to work**
* [Day 5 Exercises](exercises/day5.py)
* [More Day 5 Exercises](exercises/day5a.py)

### Day X:
**Today's Progress**: 
**Thoughts**
**Questions** 
**Link(s) to work**